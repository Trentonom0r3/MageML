## ğŸ“ˆ **Benchmarks**

> ğŸš§ **COMING SOON**  
> We'll be publishing performance benchmarks for real-time decoding, tensor throughput, and model inference speed across a variety of GPUs and presets.  
> Some nodes (like the **Read Video** node) already include built-in performance stats.

Stay tuned for:

- âš™ï¸ **FPS comparisons** for various ONNX models  
- ğŸ§ª **GPU load & VRAM usage** under real-world graph workloads  
- ğŸ” **Node-by-node runtime costs** and built-in profiling tools

---

ğŸ’¡ Want to help test or contribute benchmark data?  
Join the conversation on [Discord](https://discord.gg/hFSHjGyp4p)!
