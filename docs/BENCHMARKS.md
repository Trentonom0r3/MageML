## 📈 **Benchmarks**

> 🚧 **COMING SOON**  
> We'll be publishing performance benchmarks for real-time decoding, tensor throughput, and model inference speed across a variety of GPUs and presets.  
> Some nodes (like the **Read Video** node) already include built-in performance stats.

Stay tuned for:

- ⚙️ **FPS comparisons** for various ONNX models  
- 🧪 **GPU load & VRAM usage** under real-world graph workloads  
- 🔁 **Node-by-node runtime costs** and built-in profiling tools

---

💡 Want to help test or contribute benchmark data?  
Join the conversation on [Discord](https://discord.gg/hFSHjGyp4p)!
